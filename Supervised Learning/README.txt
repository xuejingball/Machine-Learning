1. My codes utilize the Weka library as an external library. 
2. To run my codes for supervised learning assignment, you create a project in any JAVA IDEA, such as IntelliJ which is what I am using. 
3. Open the "Project Structure" -> "Module" -> "Dependencies", or any library editing tool. Press "+" to add a JAR file, select the weka.jar in the "java code" folder, add and apply it.
4. Copy or move any JAVA file from the "java code" folder into the src folder of the newly created project. WekaAdult.java is for the Adult classification problem and WekaEcoli.java is for the Ecoli classification problem.
5. Copy or move ARFF data files from the "supporting files" folder into the src folder of the created project. For Adult problem, Adult.arff, Adult-train.arff and Adult-test.arff are respectively the entire data, the train and the test For Ecoli problem, Ecoli.arff, Ecoli-train.arff and Ecoli-test.arff are respectively the entire data, thge train and the test dataset for the Ecoli classification problem.
6. Now you can run the JAVA file by clicking “RUN” or directly run the main function in the java file.
7. Inside the main function, you can find in general three sections separated by slashes "////////". Above it, there are some self-defined helper functions.
8. The first section is where I do my data reading, splitting and shuffling, and model declarations for all algorithms.
9. The second section is to optimize the model complexity, I tuned each hyperparameter one by one. You can find each algorithm was labeled in comments and separated by dash lines "--------". In each algorithm section, you can find the corresponding parts for each hyperparameter optimization and learning curves data generation on different training sizes. All of them are currently in comments, before you run it, you should uncomment it.
10. The last section is where I test each model performance against the testing data. You can uncomment them and run all at one time. All parameters are already pre-set. 
11. For all the error rates information, I collected them from the result of my codes in the format of TXT files for each algorithm model complexity optimizing, or the learning curves against the training size, or the model performance testing results corresponding to different file names defined in the codes. 
12. I collected all the error rates information from the code generated TXT files, and organized it in CSV files and used RStudio to graph all plots shown in the analysis document. The CSV files with organized data are separated by classification problem names in the package, called “CSV-Adult” and “CSV-Ecoli” in the "supporting files" folder. The R code for generating all plots are in the package, called “dataVisulazationAdult” and “dataVisulazationEcoli”, also stored in the "supporting files" folder.
13. Besides my own code, I also used Weka Explorer GUI to obtain the training and testing time. I open the train.arff in preprocess interface, then go to the classify interface, select the algorithm to be used, change the parameters, and select “Supplied test set” in test options and load test.arff. The report after running provide the training and testing time.  
